{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52500625-ca83-4703-94da-1a040d588558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the SpaCy English model\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Enable tqdm integration with SpaCy for progress bars\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46b2339-1a1c-4c60-9391-d9582e368b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/elifakdeniz/Desktop/Thesis_New/Notebooks/Jupyter_notebook/Future Engineering/sentiment/2_final_dataset_deduplicated.csv\")  # Adjust path if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84317609-b3eb-4911-84b4-613d72f5959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e22ed37-3157-4ccc-a16d-23de3ddccb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")  # or \"en_core_web_sm\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96f173fb-41a6-437b-8d13-6ae0dbf162e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load a model with parser (md is more accurate than sm)\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=[\"ner\",\"lemmatizer\"])\n",
    "\n",
    "# Ensure we have sentence boundaries even if parser is missing\n",
    "if \"parser\" not in nlp.pipe_names:\n",
    "    if \"senter\" in nlp.pipe_names:\n",
    "        pass  # good, senter will handle sentence boundaries\n",
    "    elif \"sentencizer\" not in nlp.pipe_names:\n",
    "        nlp.add_pipe(\"sentencizer\")  # rule-based sentence splitter\n",
    "\n",
    "def compute_syntactic_features(text):\n",
    "    # Guard: ensure a clean, non-empty string\n",
    "    if not isinstance(text, str):\n",
    "        return pd.Series([0.0, 0.0], index=[\"avg_sent_len\", \"avg_tree_depth\"])\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return pd.Series([0.0, 0.0], index=[\"avg_sent_len\", \"avg_tree_depth\"])\n",
    "\n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # If sentence boundaries still missing, fall back to whole doc as one \"sentence\"\n",
    "        sents = list(doc.sents)\n",
    "        if not sents:\n",
    "            sents = [doc]\n",
    "\n",
    "        sentence_lengths = [len(sent) for sent in sents]\n",
    "\n",
    "        # tree depth: longest ancestor chain per sentence (ignore pure punctuation tokens)\n",
    "        def token_depth(tok):\n",
    "            d = 0\n",
    "            while tok.head is not tok:\n",
    "                tok = tok.head\n",
    "                d += 1\n",
    "            return d\n",
    "\n",
    "        tree_depths = []\n",
    "        for sent in sents:\n",
    "            content_toks = [t for t in sent if t.dep_ != \"punct\"]\n",
    "            if not content_toks:\n",
    "                tree_depths.append(0)\n",
    "            else:\n",
    "                tree_depths.append(max(token_depth(t) for t in content_toks))\n",
    "\n",
    "        avg_sent_len = sum(sentence_lengths) / len(sentence_lengths) if sentence_lengths else 0.0\n",
    "        avg_tree_depth = sum(tree_depths) / len(tree_depths) if tree_depths else 0.0\n",
    "\n",
    "        return pd.Series([avg_sent_len, avg_tree_depth], index=[\"avg_sent_len\", \"avg_tree_depth\"])\n",
    "    except Exception as e:\n",
    "        # Helpful for debugging instead of silent zeros:\n",
    "        # print(f\"parse error: {e}\\nText sample: {text[:200]}\")\n",
    "        return pd.Series([0.0, 0.0], index=[\"avg_sent_len\", \"avg_tree_depth\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7277a48-f438-43f7-bed7-ac485363b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler'] | nlp.max_length: 2000000\n",
      "Rows with punctuation in 'description': 100.00%\n",
      "Smoke test — sentences in first row: 18 | time: 0.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                               | 0/21063 [1:21:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     78\u001b[39m rows = []\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m tqdm(nlp.pipe(texts, batch_size=BATCH_SIZE, n_process=N_PROCESS), total=\u001b[38;5;28mlen\u001b[39m(texts)):\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     rows.append(features_from_doc(doc))\n\u001b[32m     82\u001b[39m cols = [\u001b[33m\"\u001b[39m\u001b[33mavg_sent_length\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mavg_tree_depth\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mavg_le\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mclause_count\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mn_sents\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mn_tokens\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     83\u001b[39m feats = pd.DataFrame(rows, columns=cols, index=df.index)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mfeatures_from_doc\u001b[39m\u001b[34m(doc)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sents:\n\u001b[32m     58\u001b[39m     toks = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m s \u001b[38;5;28;01mif\u001b[39;00m t.dep_ != \u001b[33m\"\u001b[39m\u001b[33mpunct\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     depths.append(\u001b[38;5;28mmax\u001b[39m((token_depth(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m toks), default=\u001b[32m0\u001b[39m))\n\u001b[32m     60\u001b[39m     clause_count += \u001b[38;5;28msum\u001b[39m(t.dep_ \u001b[38;5;129;01min\u001b[39;00m CLAUSE_DEPS \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m s)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     63\u001b[39m     (\u001b[38;5;28msum\u001b[39m(sent_lens)/\u001b[38;5;28mlen\u001b[39m(sent_lens)) \u001b[38;5;28;01mif\u001b[39;00m sent_lens \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m,   \u001b[38;5;66;03m# avg_sent_length\u001b[39;00m\n\u001b[32m     64\u001b[39m     (\u001b[38;5;28msum\u001b[39m(depths)/\u001b[38;5;28mlen\u001b[39m(depths))       \u001b[38;5;28;01mif\u001b[39;00m depths    \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m,   \u001b[38;5;66;03m# avg_tree_depth\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m     \u001b[38;5;28mlen\u001b[39m(doc),                                                \u001b[38;5;66;03m# n_tokens\u001b[39;00m\n\u001b[32m     69\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sents:\n\u001b[32m     58\u001b[39m     toks = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m s \u001b[38;5;28;01mif\u001b[39;00m t.dep_ != \u001b[33m\"\u001b[39m\u001b[33mpunct\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     depths.append(\u001b[38;5;28mmax\u001b[39m((token_depth(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m toks), default=\u001b[32m0\u001b[39m))\n\u001b[32m     60\u001b[39m     clause_count += \u001b[38;5;28msum\u001b[39m(t.dep_ \u001b[38;5;129;01min\u001b[39;00m CLAUSE_DEPS \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m s)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     63\u001b[39m     (\u001b[38;5;28msum\u001b[39m(sent_lens)/\u001b[38;5;28mlen\u001b[39m(sent_lens)) \u001b[38;5;28;01mif\u001b[39;00m sent_lens \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m,   \u001b[38;5;66;03m# avg_sent_length\u001b[39;00m\n\u001b[32m     64\u001b[39m     (\u001b[38;5;28msum\u001b[39m(depths)/\u001b[38;5;28mlen\u001b[39m(depths))       \u001b[38;5;28;01mif\u001b[39;00m depths    \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m,   \u001b[38;5;66;03m# avg_tree_depth\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m     \u001b[38;5;28mlen\u001b[39m(doc),                                                \u001b[38;5;66;03m# n_tokens\u001b[39;00m\n\u001b[32m     69\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mtoken_depth\u001b[39m\u001b[34m(tok)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtoken_depth\u001b[39m(tok):\n\u001b[32m     42\u001b[39m     d = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m tok.head \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tok:\n\u001b[32m     44\u001b[39m         tok = tok.head; d += \u001b[32m1\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === Syntactic Features: One-File Final ===\n",
    "import re, time, json, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "TEXT_COL = \"description\"                  # raw/lightly cleaned text (with punctuation + stopwords)\n",
    "BATCH_SIZE = 64                           # try 64–128; lower if RAM is limited\n",
    "N_PROCESS = 1                             # start with 1 (macOS safe); try 2–4 later\n",
    "OUT_PATH = Path(\"final_with_syntactic_features.parquet\")\n",
    "SAVE_CSV_TOO = False                      # set True if you also want a CSV\n",
    "# ------------------------------------------------\n",
    "\n",
    "# 0) Ensure column exists & not-null strings\n",
    "assert TEXT_COL in df.columns, f\"Column '{TEXT_COL}' not found in df\"\n",
    "df[TEXT_COL] = df[TEXT_COL].fillna(\"\").astype(str)\n",
    "\n",
    "# 1) Load spaCy model with parser enabled (install first: python -m spacy download en_core_web_md)\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=[\"ner\",\"lemmatizer\"])\n",
    "# safeguard for long docs\n",
    "max_chars = df[TEXT_COL].str.len().max()\n",
    "nlp.max_length = max(2_000_000, int(max_chars * 1.2))\n",
    "print(\"Pipeline:\", nlp.pipe_names, \"| nlp.max_length:\", nlp.max_length)\n",
    "\n",
    "# 2) Punctuation presence check (parsing needs it)\n",
    "def has_punct(s: str) -> bool:\n",
    "    return bool(re.search(r\"[.!?;:,()\\-]\", s or \"\"))\n",
    "\n",
    "punct_ratio = df[TEXT_COL].map(has_punct).mean()\n",
    "print(f\"Rows with punctuation in '{TEXT_COL}': {punct_ratio:.2%}\")\n",
    "if punct_ratio < 0.30:\n",
    "    raise ValueError(\n",
    "        f\"'{TEXT_COL}' appears too stripped for parsing (punctuation in only {punct_ratio:.1%} of rows). \"\n",
    "        \"Use a raw column that preserves punctuation + stopwords.\"\n",
    "    )\n",
    "\n",
    "# 3) Feature helpers\n",
    "CLAUSE_DEPS = {\"advcl\",\"ccomp\",\"xcomp\",\"acl\",\"relcl\",\"csubj\",\"csubjpass\"}\n",
    "\n",
    "def token_depth(tok):\n",
    "    d = 0\n",
    "    while tok.head is not tok:\n",
    "        tok = tok.head; d += 1\n",
    "    return d\n",
    "\n",
    "def features_from_doc(doc):\n",
    "    sents = list(doc.sents) or [doc]\n",
    "    sent_lens = [len(s) for s in sents]\n",
    "\n",
    "    # average head distance across tokens (dependency length)\n",
    "    dep_dists = [0 if t.head is t else abs(t.i - t.head.i) for t in doc]\n",
    "    avg_dep_len = float(np.mean(dep_dists)) if dep_dists else 0.0\n",
    "\n",
    "    # per-sentence max tree depth (ignore punctuation tokens)\n",
    "    depths, clause_count = [], 0\n",
    "    for s in sents:\n",
    "        toks = [t for t in s if t.dep_ != \"punct\"]\n",
    "        depths.append(max((token_depth(t) for t in toks), default=0))\n",
    "        clause_count += sum(t.dep_ in CLAUSE_DEPS for t in s)\n",
    "\n",
    "    return (\n",
    "        (sum(sent_lens)/len(sent_lens)) if sent_lens else 0.0,   # avg_sent_length\n",
    "        (sum(depths)/len(depths))       if depths    else 0.0,   # avg_tree_depth\n",
    "        avg_dep_len,                                             # avg_le\n",
    "        clause_count,                                            # clause_count\n",
    "        len(sents),                                              # n_sents\n",
    "        len(doc),                                                # n_tokens\n",
    "    )\n",
    "\n",
    "# 4) Smoke test on first row (quick sanity)\n",
    "t0 = time.time()\n",
    "doc0 = nlp(df.iloc[0][TEXT_COL])\n",
    "print(\"Smoke test — sentences in first row:\", sum(1 for _ in doc0.sents), \"| time:\", round(time.time()-t0, 2), \"s\")\n",
    "\n",
    "# 5) Batch parse entire column\n",
    "texts = df[TEXT_COL].tolist()\n",
    "rows = []\n",
    "for doc in tqdm(nlp.pipe(texts, batch_size=BATCH_SIZE, n_process=N_PROCESS), total=len(texts)):\n",
    "    rows.append(features_from_doc(doc))\n",
    "\n",
    "cols = [\"avg_sent_length\",\"avg_tree_depth\",\"avg_le\",\"clause_count\",\"n_sents\",\"n_tokens\"]\n",
    "feats = pd.DataFrame(rows, columns=cols, index=df.index)\n",
    "\n",
    "# 6) Join back + quick QA\n",
    "df = df.join(feats)\n",
    "print(df[cols].describe())\n",
    "print(\"Approx tokens check (first 10):\", (df[\"avg_sent_length\"]*df[\"n_sents\"]).head(10).round(1).to_list())\n",
    "\n",
    "# 7) Save with metadata\n",
    "meta = {\n",
    "    \"spacy_version\": spacy.__version__,\n",
    "    \"model\": \"en_core_web_md\",\n",
    "    \"pipe\": nlp.pipe_names,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"n_process\": N_PROCESS,\n",
    "    \"text_col\": TEXT_COL,\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}\n",
    "df.attrs[\"syntactic_meta\"] = json.dumps(meta)\n",
    "df.to_parquet(OUT_PATH)\n",
    "if SAVE_CSV_TOO:\n",
    "    df.to_csv(OUT_PATH.with_suffix(\".csv\"), index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_PATH)\n",
    "if SAVE_CSV_TOO:\n",
    "    print(\"Saved:\", OUT_PATH.with_suffix(\".csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c63bbe88-7258-40fe-826a-f17198705490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_dataset_with_syntactic_new_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452a742d-b426-45a0-b475-c984110176c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>pay_period</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>views</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>avg_tree_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>job descriptiona leading real estate firm in n...</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.911083</td>\n",
       "      <td>0.053122</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.022628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91700727</td>\n",
       "      <td>Downtown Raleigh Alliance</td>\n",
       "      <td>Economic Development and Planning Intern</td>\n",
       "      <td>Job summary:The Economic Development &amp; Plannin...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>1481176.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>job summarythe economic development planning i...</td>\n",
       "      <td>0.063967</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>0.584575</td>\n",
       "      <td>0.154706</td>\n",
       "      <td>0.125784</td>\n",
       "      <td>0.053150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103254301</td>\n",
       "      <td>Raw Cereal</td>\n",
       "      <td>Producer</td>\n",
       "      <td>Company DescriptionRaw Cereal is a creative de...</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>United States</td>\n",
       "      <td>81942316.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>company descriptionraw cereal is a creative de...</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.009489</td>\n",
       "      <td>0.178955</td>\n",
       "      <td>0.573286</td>\n",
       "      <td>0.016077</td>\n",
       "      <td>0.210537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9615617</td>\n",
       "      <td>Glastender, Inc.</td>\n",
       "      <td>Inside Customer Service Associate</td>\n",
       "      <td>Glastender Inc. is a family-owned manufacturer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saginaw, MI</td>\n",
       "      <td>1194336.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>glastender inc is a familyowned manufacturer o...</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.817529</td>\n",
       "      <td>0.106623</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.046128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111513530</td>\n",
       "      <td>United Methodists of Greater New Jersey</td>\n",
       "      <td>Content Writer, Communications</td>\n",
       "      <td>Application opening date: April 24, 2024\\nTitl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Greater Philadelphia</td>\n",
       "      <td>4028816.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>application opening date april title content w...</td>\n",
       "      <td>0.019976</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.809778</td>\n",
       "      <td>0.129329</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.025797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      job_id                             company_name  \\\n",
       "0     921716                    Corcoran Sawyer Smith   \n",
       "1   91700727                Downtown Raleigh Alliance   \n",
       "2  103254301                               Raw Cereal   \n",
       "3    9615617                         Glastender, Inc.   \n",
       "4  111513530  United Methodists of Greater New Jersey   \n",
       "\n",
       "                                      title  \\\n",
       "0                     Marketing Coordinator   \n",
       "1  Economic Development and Planning Intern   \n",
       "2                                  Producer   \n",
       "3         Inside Customer Service Associate   \n",
       "4            Content Writer, Communications   \n",
       "\n",
       "                                         description  max_salary pay_period  \\\n",
       "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
       "1  Job summary:The Economic Development & Plannin...        20.0     HOURLY   \n",
       "2  Company DescriptionRaw Cereal is a creative de...    300000.0     YEARLY   \n",
       "3  Glastender Inc. is a family-owned manufacturer...         NaN        NaN   \n",
       "4  Application opening date: April 24, 2024\\nTitl...         NaN        NaN   \n",
       "\n",
       "               location  company_id  views  min_salary  ...  \\\n",
       "0         Princeton, NJ   2774458.0   20.0        17.0  ...   \n",
       "1           Raleigh, NC   1481176.0    9.0        14.0  ...   \n",
       "2         United States  81942316.0    7.0     60000.0  ...   \n",
       "3           Saginaw, MI   1194336.0    4.0         NaN  ...   \n",
       "4  Greater Philadelphia   4028816.0   10.0         NaN  ...   \n",
       "\n",
       "                                   description_clean     anger   disgust  \\\n",
       "0  job descriptiona leading real estate firm in n...  0.007679  0.000650   \n",
       "1  job summarythe economic development planning i...  0.063967  0.001047   \n",
       "2  company descriptionraw cereal is a creative de...  0.010720  0.000936   \n",
       "3  glastender inc is a familyowned manufacturer o...  0.014659  0.000577   \n",
       "4  application opening date april title content w...  0.019976  0.000699   \n",
       "\n",
       "       fear       joy   neutral   sadness  surprise  avg_sent_length  \\\n",
       "0  0.001900  0.911083  0.053122  0.002938  0.022628                0   \n",
       "1  0.016772  0.584575  0.154706  0.125784  0.053150                0   \n",
       "2  0.009489  0.178955  0.573286  0.016077  0.210537                0   \n",
       "3  0.009076  0.817529  0.106623  0.005407  0.046128                0   \n",
       "4  0.005662  0.809778  0.129329  0.008757  0.025797                0   \n",
       "\n",
       "   avg_tree_depth  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the updated dataset with syntactic features\n",
    "df = pd.read_csv(\"/Users/elifakdeniz/Desktop/Thesis_New/Notebooks/Jupyter_notebook/Future Engineering/final_dataset_with_syntactic_new_features.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea18d604-1b13-43d0-96bb-7c136b7b12bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>description</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>avg_tree_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Downtown Raleigh Alliance</td>\n",
       "      <td>Non-profit Organizations</td>\n",
       "      <td>Job summary:The Economic Development &amp; Plannin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raw Cereal</td>\n",
       "      <td>Design Services</td>\n",
       "      <td>Company DescriptionRaw Cereal is a creative de...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Glastender, Inc.</td>\n",
       "      <td>Food and Beverage Services</td>\n",
       "      <td>Glastender Inc. is a family-owned manufacturer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Methodists of Greater New Jersey</td>\n",
       "      <td>Religious Institutions</td>\n",
       "      <td>Application opening date: April 24, 2024\\nTitl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shannon Waltchack</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>WORK @ SWShannon Waltchack (SW) is seeking a C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Premier Family Clinic</td>\n",
       "      <td>Hospitals and Health Care</td>\n",
       "      <td>We are seeking a qualified Physician Assistant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GOYT</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>Job Description:GOYT is seeking a skilled and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Revesco Properties</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>About Revesco Properties:Revesco Properties is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADEPT HRM Solutions</td>\n",
       "      <td>Human Resources Services</td>\n",
       "      <td>Job Summary: We are seeking a skilled Producti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              company_name                    industry  \\\n",
       "0                    Corcoran Sawyer Smith                 Real Estate   \n",
       "1                Downtown Raleigh Alliance    Non-profit Organizations   \n",
       "2                               Raw Cereal             Design Services   \n",
       "3                         Glastender, Inc.  Food and Beverage Services   \n",
       "4  United Methodists of Greater New Jersey      Religious Institutions   \n",
       "5                        Shannon Waltchack                 Real Estate   \n",
       "6                    Premier Family Clinic   Hospitals and Health Care   \n",
       "7                                     GOYT        Software Development   \n",
       "8                       Revesco Properties                 Real Estate   \n",
       "9                      ADEPT HRM Solutions    Human Resources Services   \n",
       "\n",
       "                                         description  avg_sent_length  \\\n",
       "0  Job descriptionA leading real estate firm in N...                0   \n",
       "1  Job summary:The Economic Development & Plannin...                0   \n",
       "2  Company DescriptionRaw Cereal is a creative de...                0   \n",
       "3  Glastender Inc. is a family-owned manufacturer...                0   \n",
       "4  Application opening date: April 24, 2024\\nTitl...                0   \n",
       "5  WORK @ SWShannon Waltchack (SW) is seeking a C...                0   \n",
       "6  We are seeking a qualified Physician Assistant...                0   \n",
       "7  Job Description:GOYT is seeking a skilled and ...                0   \n",
       "8  About Revesco Properties:Revesco Properties is...                0   \n",
       "9  Job Summary: We are seeking a skilled Producti...                0   \n",
       "\n",
       "   avg_tree_depth  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "8               0  \n",
       "9               0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your updated dataset\n",
    "\n",
    "# Select and display the relevant columns\n",
    "selected_columns = df[[\"company_name\", \"industry\", \"description\", \"avg_sent_length\", \"avg_tree_depth\"]]\n",
    "\n",
    "# Display the first 10 rows\n",
    "selected_columns.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7bb8a9c-ffee-4dc6-a147-4154952dc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def compute_le_nnd(text):\n",
    "    doc = nlp(text)\n",
    "    le_counts = []\n",
    "    nnd_distances = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        root = sent.root\n",
    "        le = 0\n",
    "        for token in sent:\n",
    "            if token.i < root.i and token.pos_ != \"VERB\":\n",
    "                le += 1\n",
    "        le_counts.append(le)\n",
    "\n",
    "        # NND: Nested Noun Distance\n",
    "        for token in sent:\n",
    "            if token.pos_ in {\"NOUN\", \"PROPN\"}:\n",
    "                ancestor = token.head\n",
    "                while ancestor != token and ancestor.pos_ in {\"NOUN\", \"PROPN\"}:\n",
    "                    distance = abs(token.i - ancestor.i)\n",
    "                    nnd_distances.append(distance)\n",
    "                    break  # Only consider first ancestor\n",
    "\n",
    "    avg_le = np.mean(le_counts) if le_counts else 0\n",
    "    avg_nnd = np.mean(nnd_distances) if nnd_distances else 0\n",
    "    return pd.Series([avg_le, avg_nnd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80594842-8753-4751-a9b5-6d20adb434c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 21063/21063 [34:17<00:00, 10.24it/s]\n"
     ]
    }
   ],
   "source": [
    "df[[\"avg_le\", \"avg_nnd\"]] = df[\"description_clean\"].progress_apply(compute_le_nnd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d17d48e-77ee-4ca0-bf0c-4e47ed58c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame with syntactic metrics\n",
    "df.to_csv(\"final_dataset_with_le_nnd.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925f73f-3957-4fc2-a331-2a7c9571ebc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
